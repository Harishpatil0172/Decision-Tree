# Decision Tree Algorithm

![dig10](https://user-images.githubusercontent.com/77626222/141733696-21907877-20c8-455c-99ba-c6878d5c6235.PNG)

   Decision Tree algorithm belongs to the family of supervised learning algorithms. Unlike other supervised learning algorithms, the decision tree algorithm can be used for solving regression and classification problems too.The goal of using a Decision Tree is to create a training model that can use to predict the class or value of the target variable by learning simple decision rules inferred from prior data(training data).In Decision Trees, for predicting a class label for a record we start from the root of the tree. We compare the values of the root attribute with the recordâ€™s attribute. On the basis of comparison, we follow the branch corresponding to that value and jump to the next node.   
 
 Important Terminology related to Decision Trees
 
 ![1_bcLAJfWN2GpVQNTVOCrrvw](https://user-images.githubusercontent.com/77626222/141734031-05e2ab64-0045-4bf1-818f-c954bcbccb00.png)

1. Root Node: It represents the entire population or sample and this further gets divided into two or more homogeneous sets.
2. Splitting: It is a process of dividing a node into two or more sub-nodes.
3. Decision Node: When a sub-node splits into further sub-nodes, then it is called the decision node.
4. Leaf / Terminal Node: Nodes do not split is called Leaf or Terminal node.
5. Pruning: When we remove sub-nodes of a decision node, this process is called pruning. You can say the opposite process of splitting.
6. Branch / Sub-Tree: A subsection of the entire tree is called branch or sub-tree.
7. Parent and Child Node: A node, which is divided into sub-nodes is called a parent node of sub-nodes whereas sub-nodes are the child of a parent node. 
